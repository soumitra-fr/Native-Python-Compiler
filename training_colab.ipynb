{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "026a13e9",
   "metadata": {},
   "source": [
    "# üöÄ State-of-the-Art AI Compiler Training (Google Colab)\n",
    "\n",
    "**Free GPU Training** | Tesla T4 | ~2 hours\n",
    "\n",
    "## Setup Instructions\n",
    "1. Go to: https://colab.research.google.com/\n",
    "2. File ‚Üí Upload Notebook ‚Üí Select this file\n",
    "3. Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí T4\n",
    "4. Run all cells (Ctrl+F9)\n",
    "\n",
    "## What Gets Trained\n",
    "- ‚úÖ Transformer Type Inference (GraphCodeBERT + GNN)\n",
    "- ‚úÖ Deep RL Strategy Agent (DQN + PPO)\n",
    "- ‚úÖ Meta-Learning (MAML)\n",
    "- ‚úÖ Multi-Agent System\n",
    "\n",
    "## Free GPU Options\n",
    "- **Colab**: 12-15 GB RAM, Tesla T4 GPU (free tier)\n",
    "- **Colab Pro**: $9.99/month (faster GPUs, longer sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6743ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è‚É£ Check GPU\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\n‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ Clone Your Repository from GitHub\n",
    "!git clone https://github.com/soumitra-fr/Native-Python-Compiler.git\n",
    "%cd Native-Python-Compiler\n",
    "\n",
    "print(\"\\n‚úÖ Repository cloned successfully!\")\n",
    "print(\"üìÇ All your AI code is now available in Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b7f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ Install Dependencies\n",
    "!pip install -q torch transformers scikit-learn numpy pandas tqdm huggingface_hub accelerate sentencepiece protobuf\n",
    "\n",
    "# Disable wandb (Weights & Biases) - not needed for training\n",
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "\n",
    "print(\"‚úÖ Dependencies installed\")\n",
    "print(\"‚úÖ Wandb logging disabled (not needed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486d2b8d",
   "metadata": {},
   "source": [
    "## üìö Generate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d948b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content/Native-Python-Compiler')\n",
    "\n",
    "# Generate type inference training data\n",
    "def generate_type_training_data(num_samples=2000):\n",
    "    \"\"\"Generate diverse type inference examples\"\"\"\n",
    "    training_data = []\n",
    "    \n",
    "    patterns = [\n",
    "        # Basic types\n",
    "        (\"x = {}\", \"x\", \"int\", list(range(100))),\n",
    "        (\"y = {}\", \"y\", \"float\", [i * 0.5 for i in range(100)]),\n",
    "        (\"s = '{}'\", \"s\", \"str\", [f\"string_{i}\" for i in range(100)]),\n",
    "        (\"flag = {}\", \"flag\", \"bool\", [True, False] * 50),\n",
    "        \n",
    "        # Collections\n",
    "        (\"lst = {}\", \"lst\", \"list\", [[i, i+1, i+2] for i in range(100)]),\n",
    "        (\"d = {}\", \"d\", \"dict\", [{f'k{i}': i} for i in range(100)]),\n",
    "        (\"t = {}\", \"t\", \"tuple\", [(i, i+1) for i in range(100)]),\n",
    "        (\"s = {}\", \"s\", \"set\", [{i, i+1, i+2} for i in range(100)]),\n",
    "        \n",
    "        # Complex patterns\n",
    "        (\"result = {} + 10\", \"result\", \"int\", list(range(100))),\n",
    "        (\"total = sum({})\", \"total\", \"int\", [[1,2,3], [4,5], [6,7,8,9]] * 33),\n",
    "        (\"items = [x*2 for x in {}]\", \"items\", \"list\", [range(10), range(5)] * 50),\n",
    "    ]\n",
    "    \n",
    "    for pattern, var, type_label, values in patterns:\n",
    "        for value in values:\n",
    "            code = pattern.format(repr(value))\n",
    "            training_data.append({\n",
    "                'code': code,\n",
    "                'variable': var,\n",
    "                'type': type_label\n",
    "            })\n",
    "    \n",
    "    return training_data\n",
    "\n",
    "print(\"üìä Generating training data...\")\n",
    "train_data = generate_type_training_data(2000)\n",
    "val_data = generate_type_training_data(400)\n",
    "\n",
    "print(f\"‚úÖ Training samples: {len(train_data)}\")\n",
    "print(f\"‚úÖ Validation samples: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7ad55",
   "metadata": {},
   "source": [
    "## üß† Train Type Inference (GraphCodeBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e3f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai.transformer_type_inference import TransformerTypeInferenceEngine\n",
    "import time\n",
    "import torch\n",
    "\n",
    "print(\"1Ô∏è‚É£  Training Transformer Type Inference...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Clear GPU cache before training\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "engine = TransformerTypeInferenceEngine(device=\"cuda\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "engine.train(\n",
    "    training_data=train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=3,  # Reduced from 10 to save memory\n",
    "    batch_size=8,  # Reduced from 32 to fit in GPU memory\n",
    "    learning_rate=2e-5,\n",
    "    output_dir=\"./ai/models/type_inference_gpu\"\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Training complete in {training_time:.1f}s ({training_time/60:.1f} min)\")\n",
    "\n",
    "# Clear cache after training\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Test\n",
    "test_code = \"count = 42\\nresult = count * 2\"\n",
    "pred = engine.predict(test_code, \"count\")\n",
    "print(f\"\\nüß™ Test: {pred.type_name} (confidence: {pred.confidence:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd68f995",
   "metadata": {},
   "source": [
    "## ü§ñ Train DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0172a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai.deep_rl_strategy import DeepRLStrategyAgent\n",
    "\n",
    "print(\"2Ô∏è‚É£  Training DQN Strategy Agent...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "dqn_agent = DeepRLStrategyAgent(device=\"cuda\", batch_size=64, buffer_size=50000)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "dqn_agent.train(training_episodes=1000, eval_freq=100)  # More episodes on GPU\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Training complete in {training_time:.1f}s ({training_time/60:.1f} min)\")\n",
    "\n",
    "dqn_agent.save(\"./ai/models/dqn_gpu\")\n",
    "print(\"üíæ Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb87a7b8",
   "metadata": {},
   "source": [
    "## üéØ Train PPO Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0a8faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai.ppo_agent import PPOAgent\n",
    "\n",
    "print(\"3Ô∏è‚É£  Training PPO Agent...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "ppo_agent = PPOAgent(device=\"cuda\", batch_size=64)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "ppo_agent.train(num_episodes=1000, steps_per_episode=100)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Training complete in {training_time:.1f}s ({training_time/60:.1f} min)\")\n",
    "\n",
    "ppo_agent.save(\"./ai/models/ppo_gpu\")\n",
    "print(\"üíæ Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f242478",
   "metadata": {},
   "source": [
    "## üîÑ Train MAML Meta-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d785253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai.meta_learning import MAMLAgent, generate_synthetic_tasks\n",
    "\n",
    "print(\"4Ô∏è‚É£  Training MAML Meta-Learning...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "maml_agent = MAMLAgent(device=\"cuda\")\n",
    "\n",
    "train_tasks = generate_synthetic_tasks(100)\n",
    "val_tasks = generate_synthetic_tasks(20)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "maml_agent.meta_train(train_tasks, val_tasks, num_iterations=500, tasks_per_batch=8)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Training complete in {training_time:.1f}s ({training_time/60:.1f} min)\")\n",
    "\n",
    "maml_agent.save(\"./ai/models/maml_gpu\")\n",
    "print(\"üíæ Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b3dd8e",
   "metadata": {},
   "source": [
    "## üíæ Download Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d877c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package all trained models\n",
    "!zip -r trained_models.zip ai/models/\n",
    "\n",
    "print(\"\\n‚úÖ All models packaged!\")\n",
    "print(\"\\nüì• Download 'trained_models.zip' from Colab Files panel (left sidebar)\")\n",
    "print(\"\\nüìù Extract on your Mac:\")\n",
    "print(\"   unzip trained_models.zip\")\n",
    "print(\"   # Models will be in ai/models/ directory\")\n",
    "\n",
    "from google.colab import files\n",
    "files.download('trained_models.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64412b6f",
   "metadata": {},
   "source": [
    "## üìä Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44b2313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "summary = {\n",
    "    \"device\": \"GPU (Colab)\",\n",
    "    \"gpu_type\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\",\n",
    "    \"components_trained\": [\n",
    "        \"Transformer Type Inference (GraphCodeBERT)\",\n",
    "        \"DQN Strategy Agent (Dueling DQN + PER)\",\n",
    "        \"PPO Agent (Actor-Critic + GAE)\",\n",
    "        \"MAML Meta-Learning\"\n",
    "    ],\n",
    "    \"training_data_size\": len(train_data),\n",
    "    \"validation_data_size\": len(val_data),\n",
    "    \"status\": \"COMPLETE\",\n",
    "    \"next_steps\": [\n",
    "        \"Download trained_models.zip\",\n",
    "        \"Extract to your Mac project\",\n",
    "        \"Test with: python3 ai/test_trained_models.py\",\n",
    "        \"Run benchmarks: python3 ai/benchmark_ai_components.py\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(json.dumps(summary, indent=2))\n",
    "\n",
    "with open('training_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\nüíæ Summary saved to training_summary.json\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
